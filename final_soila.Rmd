# Final Assignment

## Authors infrormation:
  ---
title: "Final Assignment"
author: "Tuomas Soila"
date: "6 3 2017"
email: tuomas.soila@helsinki.fi
output: html_document
---



## Research question:
This research will look into the Alcohol consumption dataset. First I will do k-means clustering on the data and then do Linear discriminant analysis on the clusters based on the k-means clustering. My hypothesis is that parents’ education will have influence on the clusters.  

## A link to your data wrangling script. 
Here is a link to my data wrangling file
https://github.com/Mannerheim/IODS-project/blob/master/data/final_assignment_data_wrangling_soila.R


##part 1 
Reading the file and printing the column names and glimpsing the data. The data comes from https://archive.ics.uci.edu/ml/datasets/STUDENT+ALCOHOL+CONSUMPTION. The data are from two identical questionnaires related to secondary school student alcohol consumption in Portugal.
```{r}
alc <- read.table("/Users/Tuomassoila/IODS-project/data/alc_use_final_assignment.txt", sep = "," , header=TRUE)
colnames(alc)
glimpse(alc)

```
The data consist of two separate datasets that have been combined to one. Attributes for both student-mat.csv (Math course) and student-por.csv (Portuguese language course) are printed above. It has 35 variables and 382 observations. Such variables as: sex, family size, age...



##part 3
I produced visual and numerical explorations of the variables. I produced the distributions and correlations in the data. Correlations were produced as numbers and visuals. 

```{r}
library(FactoMineR)
library(ggplot2)
library(dplyr)
library(tidyr)
library(corrplot)
library(GGally)
#modifying the data to observe only the numerical variables
keep_columns <- c("absences", "Dalc","Walc", "goout", "freetime","famrel", "failures", "studytime", "traveltime", "Fedu", "Medu", "age","G3")
alc_lda <- dplyr::select(alc, one_of(keep_columns))
#producing distributions as barplots for all variables
gather(alc_lda) %>% ggplot(aes(value)) + geom_bar()+theme(axis.text.x = element_text(angle = 45, hjust= 1, size = 8)) + facet_wrap("key",scales = "free")

#producing a correlation matrix of the variables. 
cor(alc_lda)%>% corrplot()
cor_matrix<-cor(alc_lda) %>% round(digits=2)
cor_matrix
```
Most of the variables except for age are, goout, freetime, studytime, famrel not really normally distributed. For correlations, there are not many obvious correlations. Failures is (-0.37) quite strongly negatively correlated with the finald grade. And not surprisingly alcohol use is correlated with going out. Also, there is -0.26 correlation between studytime and weekend alcohol use. Also mother's and father's education levels are correlated strongly with 0.6. Mother's education has a positive correlation with final grade (0.24). 



## Part 3 
Brief description of the method

I am using  k-means clustering and linear discriminant analysis and linear regression analysis. Linear discriminant analysis is a classification method that finds linear combination to divide the target variable. The target variable can be categorical or binary. The methods is closely linked to other dimensionality reduction methods and also regression analysis. K-means clustering is an unsupervised clustering method which aims to create clusters for n observations by allocating observations based on similarity of the objects. 


## Part 4

I first calculated the Euclidian distance from the data. Then calculated the total sum of squares and visualised the results. I then continued to run the k-means clustering algorithm with 3 centres since the steepest change is between 2 and 3. I plotted the pairwise comparisons. Then I fitted the Linear discriminant analysis with the k-means clusters as the target variable and other variables as predicator variables. Then I plotted the whole thing with variables as arrows. 

```{r}

dist_eu <- dist(alc_lda)
#adding the max number of clusters first 15 and then 3 as this was the optimal. 
k_max <- 15
# calculating the total with sum of squares 
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})

# visualising the results 
plot(1:k_max, twcss, type='b')

# running the k-means clustering
km2 <-kmeans(dist_eu, centers = 3)

#plotting the alc dataset with clusters
pairs(alc_lda, col = km2$cluster)

lda.fit <- lda(km2$cluster ~ ., data = alc_lda)
lda.fit
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}


plot(lda.fit, dimen = 3, col = km2$cluster, pch = km2$cluster)
lda.arrows(lda.fit, myscale = 1)
```
From the matrix we can gather that absences and grades (G3) seem to be useful on disrciminating the clusters. For absences there are clear patterns between the different colours. 

The LDA model covers 96% of the variance between groups. The LD2 only covers 4.1% of the variance and influential discriminant on this dimension are Daily alcohol use (DALC) and negative influence Family relations (famrel) -0.49616 and traveltime -0.533.  In the LDA biplot we have the classes in different colour and the variables in the middle. The direction and length of the arrow displays how the variable impacts the model and these are based on the coefficients. In the LDA coefficients we can see that Absences is the most influential linear discriminant. 
In the biplot we can observe three clearly separate clusters. So after running the k-means algorithm the assumption was that absences and grades might be influencial discriminants in the data. After running LDA on the created clusters we can gather that Absences is a meaningful discriminant in the data. 

The original hypothesis that parents education would be an influential discriminant can be rejected since in the LDA it's effect is not important (LDI1: Fedu 0.00529 and Medu -0.0021).


## Part 5

I first prepared the data by removing others than numerical variables. 
I then performed k-means clustering and Linear discriminant analysis on the alcohol consumption dataset. 
With the K-means clustering three clusters were found in the data. From plotting this I concluded that absences would be a good variable to use to identify clusters. 
Then I did Linear discriminant analysis on the k-means clusters, fro which it can be gathered that absences was a good discriminating variable with the value ( -0.325201542). In the biplot three clusters we clearly visible. So my original hypothesis can be disregarded.  


## Part 6
•	An ‘abstract’ at the beginning of the page with a summary of your analysis (max 2 points)
I wrangled two datasets together and investigated the dimensions of the data. My hypothesis is that the parents' education has an affect on the clusters in the data.  I removed all other than numerical variables from the data. Then I did K-means clustering on the dataset finding 3 separate clusters from the data with the assumption that absences and Grades would be good discriminating variables. I then continued to run Linear Discriminant analysis on the clusters gathered from the k-means analysis. From the LDA I found that absences was an influential discriminating variable. So my original hypothesis can be disregarded.   
